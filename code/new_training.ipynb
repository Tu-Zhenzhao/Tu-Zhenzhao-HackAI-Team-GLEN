{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff2c217e-5dfc-4180-b2a5-a16ff7ae582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "import pandas as pd\n",
    "import re\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42724a3f-29ec-4709-a0cf-daddb947510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test see if GPU is ready\n",
    "def check_gpu():\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA is ready!\")\n",
    "        device = torch.cuda.get_device_name(0)\n",
    "        print(f\"{device} is ready!\")\n",
    "    else:\n",
    "        print(\"CUDA is gone...\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ec04c2d-784b-4b15-8f7f-64fef138b24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is ready!\n",
      "NVIDIA GeForce RTX 4090 is ready!\n"
     ]
    }
   ],
   "source": [
    "check_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3047ec9d-a39e-4104-bbe4-aa5493d849f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the model info\n",
    "base_model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "#dataset_name = \"arxiv_papers\"\n",
    "new_model = \"/project/models/NV-llama3.1-8b-Arxiv\"\n",
    "api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41ffa6bf-2ac4-4d2c-8d82-6f170695dcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "data = pd.read_csv(\"ml_papers.csv\")\n",
    "data = data.dropna(subset=['title', 'summary']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ac0be7a-532b-42f0-8ccf-082a99d4ec50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>arxiv_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agents in Software Engineering: Survey, Landsc...</td>\n",
       "      <td>In recent years, Large Language Models (LLMs) ...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09030v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.09030v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Learning Theory Informed Priors for Bayesian I...</td>\n",
       "      <td>Cosmological models are often motivated and fo...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09029v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.09029v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Towards Leveraging Contrastively Pretrained Ne...</td>\n",
       "      <td>Music recommender systems frequently utilize n...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09026v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.09026v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INN-PAR: Invertible Neural Network for PPG to ...</td>\n",
       "      <td>Non-invasive and continuous blood pressure (BP...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09021v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.09021v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An Efficient and Streaming Audio Visual Active...</td>\n",
       "      <td>This paper delves into the challenging task of...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09018v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.09018v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Closed-Loop Visuomotor Control with Generative...</td>\n",
       "      <td>Despite significant progress in robotics and e...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09016v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.09016v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AI-LieDar: Examine the Trade-off Between Utili...</td>\n",
       "      <td>To be safely and successfully deployed, LLMs m...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09013v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.09013v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VAE Explainer: Supplement Learning Variational...</td>\n",
       "      <td>Variational Autoencoders are widespread in Mac...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09011v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.09011v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Contri(e)ve: Context + Retrieve for Scholarly ...</td>\n",
       "      <td>Scholarly communication is a rapid growing fie...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09010v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.09010v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Optimizing Rare Word Accuracy in Direct Speech...</td>\n",
       "      <td>Direct speech translation (ST) models often st...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09009v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.09009v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chiral dark matter and radiative neutrino mass...</td>\n",
       "      <td>We propose a class of dark matter models based...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09008v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.09008v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SGFormer: Single-Layer Graph Transformers with...</td>\n",
       "      <td>Learning representations on large graphs is a ...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09007v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.09007v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Model-independent variable selection via the r...</td>\n",
       "      <td>While achieving high prediction accuracy is a ...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09003v2</td>\n",
       "      <td>http://arxiv.org/abs/2409.09003v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>E2MoCase: A Dataset for Emotional, Event and M...</td>\n",
       "      <td>The way media reports on legal cases can signi...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09001v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.09001v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dark Matter Axion Search with HAYSTAC Phase II</td>\n",
       "      <td>This Letter reports new results from the HAYST...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.08998v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.08998v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Biomimetic Frontend for Differentiable Audio P...</td>\n",
       "      <td>While models in audio and speech processing ar...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.08997v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.08997v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Diffusion crossover from/to $q$-statistics to/...</td>\n",
       "      <td>We study the angular diffusion in a classical ...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.08992v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.08992v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Comparative Analysis of Pretrained Audio Repre...</td>\n",
       "      <td>Over the years, Music Information Retrieval (M...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.08987v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.08987v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The connection of polaritonic chemistry with t...</td>\n",
       "      <td>Polaritonic chemistry has garnered increasing ...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.08986v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.08986v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Clean Label Attacks against SLU Systems</td>\n",
       "      <td>Poisoning backdoor attacks involve an adversar...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.08985v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.08985v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   Agents in Software Engineering: Survey, Landsc...   \n",
       "1   Learning Theory Informed Priors for Bayesian I...   \n",
       "2   Towards Leveraging Contrastively Pretrained Ne...   \n",
       "3   INN-PAR: Invertible Neural Network for PPG to ...   \n",
       "4   An Efficient and Streaming Audio Visual Active...   \n",
       "5   Closed-Loop Visuomotor Control with Generative...   \n",
       "6   AI-LieDar: Examine the Trade-off Between Utili...   \n",
       "7   VAE Explainer: Supplement Learning Variational...   \n",
       "8   Contri(e)ve: Context + Retrieve for Scholarly ...   \n",
       "9   Optimizing Rare Word Accuracy in Direct Speech...   \n",
       "10  Chiral dark matter and radiative neutrino mass...   \n",
       "11  SGFormer: Single-Layer Graph Transformers with...   \n",
       "12  Model-independent variable selection via the r...   \n",
       "13  E2MoCase: A Dataset for Emotional, Event and M...   \n",
       "14     Dark Matter Axion Search with HAYSTAC Phase II   \n",
       "15  Biomimetic Frontend for Differentiable Audio P...   \n",
       "16  Diffusion crossover from/to $q$-statistics to/...   \n",
       "17  Comparative Analysis of Pretrained Audio Repre...   \n",
       "18  The connection of polaritonic chemistry with t...   \n",
       "19            Clean Label Attacks against SLU Systems   \n",
       "\n",
       "                                              summary  \\\n",
       "0   In recent years, Large Language Models (LLMs) ...   \n",
       "1   Cosmological models are often motivated and fo...   \n",
       "2   Music recommender systems frequently utilize n...   \n",
       "3   Non-invasive and continuous blood pressure (BP...   \n",
       "4   This paper delves into the challenging task of...   \n",
       "5   Despite significant progress in robotics and e...   \n",
       "6   To be safely and successfully deployed, LLMs m...   \n",
       "7   Variational Autoencoders are widespread in Mac...   \n",
       "8   Scholarly communication is a rapid growing fie...   \n",
       "9   Direct speech translation (ST) models often st...   \n",
       "10  We propose a class of dark matter models based...   \n",
       "11  Learning representations on large graphs is a ...   \n",
       "12  While achieving high prediction accuracy is a ...   \n",
       "13  The way media reports on legal cases can signi...   \n",
       "14  This Letter reports new results from the HAYST...   \n",
       "15  While models in audio and speech processing ar...   \n",
       "16  We study the angular diffusion in a classical ...   \n",
       "17  Over the years, Music Information Retrieval (M...   \n",
       "18  Polaritonic chemistry has garnered increasing ...   \n",
       "19  Poisoning backdoor attacks involve an adversar...   \n",
       "\n",
       "                              pdf_url                         arxiv_link  \n",
       "0   http://arxiv.org/pdf/2409.09030v1  http://arxiv.org/abs/2409.09030v1  \n",
       "1   http://arxiv.org/pdf/2409.09029v1  http://arxiv.org/abs/2409.09029v1  \n",
       "2   http://arxiv.org/pdf/2409.09026v1  http://arxiv.org/abs/2409.09026v1  \n",
       "3   http://arxiv.org/pdf/2409.09021v1  http://arxiv.org/abs/2409.09021v1  \n",
       "4   http://arxiv.org/pdf/2409.09018v1  http://arxiv.org/abs/2409.09018v1  \n",
       "5   http://arxiv.org/pdf/2409.09016v1  http://arxiv.org/abs/2409.09016v1  \n",
       "6   http://arxiv.org/pdf/2409.09013v1  http://arxiv.org/abs/2409.09013v1  \n",
       "7   http://arxiv.org/pdf/2409.09011v1  http://arxiv.org/abs/2409.09011v1  \n",
       "8   http://arxiv.org/pdf/2409.09010v1  http://arxiv.org/abs/2409.09010v1  \n",
       "9   http://arxiv.org/pdf/2409.09009v1  http://arxiv.org/abs/2409.09009v1  \n",
       "10  http://arxiv.org/pdf/2409.09008v1  http://arxiv.org/abs/2409.09008v1  \n",
       "11  http://arxiv.org/pdf/2409.09007v1  http://arxiv.org/abs/2409.09007v1  \n",
       "12  http://arxiv.org/pdf/2409.09003v2  http://arxiv.org/abs/2409.09003v2  \n",
       "13  http://arxiv.org/pdf/2409.09001v1  http://arxiv.org/abs/2409.09001v1  \n",
       "14  http://arxiv.org/pdf/2409.08998v1  http://arxiv.org/abs/2409.08998v1  \n",
       "15  http://arxiv.org/pdf/2409.08997v1  http://arxiv.org/abs/2409.08997v1  \n",
       "16  http://arxiv.org/pdf/2409.08992v1  http://arxiv.org/abs/2409.08992v1  \n",
       "17  http://arxiv.org/pdf/2409.08987v1  http://arxiv.org/abs/2409.08987v1  \n",
       "18  http://arxiv.org/pdf/2409.08986v1  http://arxiv.org/abs/2409.08986v1  \n",
       "19  http://arxiv.org/pdf/2409.08985v1  http://arxiv.org/abs/2409.08985v1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ddbe8cb-312c-48c6-bbde-ddc9fb000058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract topics from titles\n",
    "def extract_topic(title):\n",
    "    title = re.sub(r\"\\(.*?\\)|\\[.*?\\]\", \"\", title)\n",
    "    title = re.sub(r'[^\\w\\s]', '', title)\n",
    "    title = title.lower()\n",
    "    return title.strip()\n",
    "\n",
    "# Generate user queries\n",
    "def generate_user_query(topic):\n",
    "    return f\"I'm looking for papers discussing {topic}.\"\n",
    "\n",
    "# Create assistant responses\n",
    "def create_assistant_response(row):\n",
    "    title = row['title']\n",
    "    summary = row['summary']\n",
    "    response = f\"One paper that discusses this topic is '{title}'. {summary}\"\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "498f76dd-bc73-467c-9359-fad4e4f47d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['topic'] = data['title'].apply(extract_topic)\n",
    "data['instruction'] = data['topic'].apply(generate_user_query)\n",
    "\n",
    "# generate assistant responses\n",
    "data['response'] = data.apply(create_assistant_response, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "425f9e63-5732-43e8-b12d-11d67495b4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>arxiv_link</th>\n",
       "      <th>topic</th>\n",
       "      <th>instruction</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agents in Software Engineering: Survey, Landsc...</td>\n",
       "      <td>In recent years, Large Language Models (LLMs) ...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09030v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.09030v1</td>\n",
       "      <td>agents in software engineering survey landscap...</td>\n",
       "      <td>I'm looking for papers discussing agents in so...</td>\n",
       "      <td>One paper that discusses this topic is 'Agents...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Learning Theory Informed Priors for Bayesian I...</td>\n",
       "      <td>Cosmological models are often motivated and fo...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09029v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.09029v1</td>\n",
       "      <td>learning theory informed priors for bayesian i...</td>\n",
       "      <td>I'm looking for papers discussing learning the...</td>\n",
       "      <td>One paper that discusses this topic is 'Learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Towards Leveraging Contrastively Pretrained Ne...</td>\n",
       "      <td>Music recommender systems frequently utilize n...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09026v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.09026v1</td>\n",
       "      <td>towards leveraging contrastively pretrained ne...</td>\n",
       "      <td>I'm looking for papers discussing towards leve...</td>\n",
       "      <td>One paper that discusses this topic is 'Toward...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INN-PAR: Invertible Neural Network for PPG to ...</td>\n",
       "      <td>Non-invasive and continuous blood pressure (BP...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09021v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.09021v1</td>\n",
       "      <td>innpar invertible neural network for ppg to ab...</td>\n",
       "      <td>I'm looking for papers discussing innpar inver...</td>\n",
       "      <td>One paper that discusses this topic is 'INN-PA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An Efficient and Streaming Audio Visual Active...</td>\n",
       "      <td>This paper delves into the challenging task of...</td>\n",
       "      <td>http://arxiv.org/pdf/2409.09018v1</td>\n",
       "      <td>http://arxiv.org/abs/2409.09018v1</td>\n",
       "      <td>an efficient and streaming audio visual active...</td>\n",
       "      <td>I'm looking for papers discussing an efficient...</td>\n",
       "      <td>One paper that discusses this topic is 'An Eff...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Agents in Software Engineering: Survey, Landsc...   \n",
       "1  Learning Theory Informed Priors for Bayesian I...   \n",
       "2  Towards Leveraging Contrastively Pretrained Ne...   \n",
       "3  INN-PAR: Invertible Neural Network for PPG to ...   \n",
       "4  An Efficient and Streaming Audio Visual Active...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  In recent years, Large Language Models (LLMs) ...   \n",
       "1  Cosmological models are often motivated and fo...   \n",
       "2  Music recommender systems frequently utilize n...   \n",
       "3  Non-invasive and continuous blood pressure (BP...   \n",
       "4  This paper delves into the challenging task of...   \n",
       "\n",
       "                             pdf_url                         arxiv_link  \\\n",
       "0  http://arxiv.org/pdf/2409.09030v1  http://arxiv.org/abs/2409.09030v1   \n",
       "1  http://arxiv.org/pdf/2409.09029v1  http://arxiv.org/abs/2409.09029v1   \n",
       "2  http://arxiv.org/pdf/2409.09026v1  http://arxiv.org/abs/2409.09026v1   \n",
       "3  http://arxiv.org/pdf/2409.09021v1  http://arxiv.org/abs/2409.09021v1   \n",
       "4  http://arxiv.org/pdf/2409.09018v1  http://arxiv.org/abs/2409.09018v1   \n",
       "\n",
       "                                               topic  \\\n",
       "0  agents in software engineering survey landscap...   \n",
       "1  learning theory informed priors for bayesian i...   \n",
       "2  towards leveraging contrastively pretrained ne...   \n",
       "3  innpar invertible neural network for ppg to ab...   \n",
       "4  an efficient and streaming audio visual active...   \n",
       "\n",
       "                                         instruction  \\\n",
       "0  I'm looking for papers discussing agents in so...   \n",
       "1  I'm looking for papers discussing learning the...   \n",
       "2  I'm looking for papers discussing towards leve...   \n",
       "3  I'm looking for papers discussing innpar inver...   \n",
       "4  I'm looking for papers discussing an efficient...   \n",
       "\n",
       "                                            response  \n",
       "0  One paper that discusses this topic is 'Agents...  \n",
       "1  One paper that discusses this topic is 'Learni...  \n",
       "2  One paper that discusses this topic is 'Toward...  \n",
       "3  One paper that discusses this topic is 'INN-PA...  \n",
       "4  One paper that discusses this topic is 'An Eff...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2dfe12dc-7ec3-41ee-aab6-79f8107c39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define special tokens\n",
    "bos_token = \"<bos>\"\n",
    "eos_token = \"<eos>\"\n",
    "user_start = \"<user>\"\n",
    "user_end = \"</user>\"\n",
    "assistant_start = \"<assistant>\"\n",
    "assistant_end = \"</assistant>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b5a5219-912c-4a07-b8ab-549275414f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format examples\n",
    "def format_example(instruction, response):\n",
    "    return f\"{bos_token}\\n{user_start}\\n{instruction}\\n{user_end}\\n{assistant_start}\\n{response}\\n{assistant_end}\\n{eos_token}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b98bc350-4b67-4244-87c0-c67813d0ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data.apply(lambda row: format_example(row['instruction'], row['response']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2fad6b92-cce3-4b0a-a83e-2f17347a5074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9579f2773c5347e89ba0b17e0c7fde61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import the model and configure it\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# Setup the BitsAndBytesConfig for 8-bit quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Load model in 8-bit precision\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    token=api_key, \n",
    ")\n",
    "\n",
    "special_tokens = {\n",
    "    'bos_token': bos_token,\n",
    "    'eos_token': eos_token,\n",
    "    'additional_special_tokens': [user_start, user_end, assistant_start, assistant_end]\n",
    "}\n",
    "\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "\n",
    "# Set pad_token as eos_token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, \n",
    "                                             token=api_key, \n",
    "                                             quantization_config=bnb_config,\n",
    "                                             cache_dir=\"/project/models\",\n",
    "                                             device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38c6a048-9285-4032-aaa7-610013e28b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(128262, 4096)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update model embeddings\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56440cc5-ef96-4584-a9a4-c949cc02fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    ")\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f016f013-6e13-41f6-903d-3a8f2e6f1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize data\n",
    "tokenized_data = tokenizer(\n",
    "    data['text'].tolist(),\n",
    "    padding='longest',\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb24df5e-24b7-4037-b322-421b7e421ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "class PapersDataset(Dataset):\n",
    "    def __init__(self, tokenized_data):\n",
    "        self.input_ids = tokenized_data['input_ids']\n",
    "        self.attention_mask = tokenized_data['attention_mask']\n",
    "        self.labels = tokenized_data['input_ids'].clone()\n",
    "\n",
    "        assistant_start_id = tokenizer.convert_tokens_to_ids(assistant_start)\n",
    "        assistant_end_id = tokenizer.convert_tokens_to_ids(assistant_end)\n",
    "\n",
    "        for i in range(len(self.labels)):\n",
    "            input_ids = self.input_ids[i]\n",
    "            labels = self.labels[i]\n",
    "\n",
    "            assistant_start_positions = (input_ids == assistant_start_id).nonzero(as_tuple=True)[0]\n",
    "            assistant_end_positions = (input_ids == assistant_end_id).nonzero(as_tuple=True)[0]\n",
    "\n",
    "            if len(assistant_start_positions) > 0 and len(assistant_end_positions) > 0:\n",
    "                assistant_start_pos = assistant_start_positions[0]\n",
    "                assistant_end_pos = assistant_end_positions[0]\n",
    "\n",
    "                labels[:assistant_start_pos + 1] = -100\n",
    "                labels[assistant_end_pos:] = -100\n",
    "            else:\n",
    "                labels[:] = -100\n",
    "\n",
    "            self.labels[i] = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_mask[idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2e264f23-6728-431f-b2dd-a007d5bd1f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PapersDataset(tokenized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "797798e1-ef05-4fbc-8278-f221a43bb064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.PapersDataset at 0x7f87983044f0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38fcccf5-7bba-4bf2-9010-6cef157d9284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    fp16=True,\n",
    "    learning_rate=2e-5,\n",
    "    save_total_limit=2,\n",
    "    save_steps=500,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"no\",\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "14d983ad-19c5-4049-8bf4-dca600179cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workbench/.local/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=dataset,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b76cbd-434d-4374-a4e7-12e29d6caa92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
