{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b3ca910-40a7-483b-9b71-2a50244d13a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the model info\n",
    "base_model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "new_model = \"/project/models/NV-llama3.1-8b-Arxiv\"\n",
    "api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddc76a33-be8d-405a-b05e-3b09a9b31f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your special tokens\n",
    "bos_token = \"<bos>\"\n",
    "eos_token = \"<eos>\"\n",
    "pad_token = \"<pad>\"\n",
    "user_start = \"<user>\"\n",
    "user_end = \"</user>\"\n",
    "assistant_start = \"<assistant>\"\n",
    "assistant_end = \"</assistant>\"\n",
    "\n",
    "special_tokens = {\n",
    "    'bos_token': bos_token,\n",
    "    'eos_token': eos_token,\n",
    "    'pad_token': pad_token,\n",
    "    'additional_special_tokens': [user_start, user_end, assistant_start, assistant_end]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66313b49-47dc-4b22-823c-a5b36ae66e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the BitsAndBytesConfig for 8-bit quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Load model in 8-bit precision\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77cec062-4ec8-47ce-bcac-e0fed0e76377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427f331e1d644c538c0ffc576ca30d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Embedding(128263, 4096)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    token=api_key\n",
    ")\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "tokenizer.pad_token = pad_token\n",
    "\n",
    "\n",
    "# Load the base model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    token=api_key,\n",
    "    quantization_config=bnb_config,\n",
    "    cache_dir=\"/project/models\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Update model's embeddings to accommodate new tokens\n",
    "base_model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8334aa8d-f2eb-4b85-93d5-bfbf61472006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "peft_model = PeftModel.from_pretrained(base_model, \"/project/models/arxiv_model\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05ef1cd4-4700-4fcb-b607-c848b1bba5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the format_example function\n",
    "def format_example(instruction, response=\"\"):\n",
    "    return f\"{bos_token}\\n{user_start}\\n{instruction}\\n{user_end}\\n{assistant_start}\\n{response}\"\n",
    "\n",
    "# Prepare the input\n",
    "instruction = \"I am looking for a paper discussing You Only Read Once(YORO).\"\n",
    "input_text = format_example(instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5eedd01-6f49-4998-915a-7d442528c2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input\n",
    "inputs = tokenizer(\n",
    "    input_text,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    padding=True\n",
    ").to(\"cuda\")\n",
    "\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "attention_mask = inputs[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "304b7d45-4a22-4508-a382-becb140c1895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><bos>\n",
      "<user>\n",
      "I am looking for a paper discussing You Only Read Once(YORO).\n",
      "</user>\n",
      "<assistant>\n",
      "One paper that discusses this topic is 'You Only Read Once (YORO): Exploring the Paradox of Reading Without Improving Comprehension\". While it is widely believed that reading improves language model\n",
      "comprehension and general knowledge, a recent study has surprisingly found that\n",
      "this assumption may be a misconception. Based on this finding, this work\n",
      "proposes a new reading strategy that only requires a model to read an article\n",
      "once without any subsequent testing or evaluation, i.e. YORO. We investigate\n",
      "the effectiveness of YORO by evaluating models' comprehension, knowledge, and\n",
      "performance in related tasks both before and after the reading process.\n",
      "Surprisingly, our results show that YORO is effective in improving models'\n",
      "comprehension, general knowledge, and performance in related tasks. However,\n",
      "under different evaluation settings, YORO only leads to positive changes in\n",
      "language models with limited initial knowledge and comprehension. We further\n",
      "investigate potential factors influencing the effectiveness of YORO, including\n",
      "model architectures, training data, and related task difficulty. Our\n",
      "experiments demonstrate that YORO only benefits models that require improved\n",
      "comprehension and knowledge to pass related tasks, while it has no impact on\n",
      "other models. Our work provides new insights into the reading strategy that\n",
      "language models should follow and challenges the current belief that reading is\n",
      "an effective approach to improving language models' comprehension and\n",
      "general knowledge.\n",
      "opensource\n",
      "You Only Read Once (YORO) proposes a counter-intuitive reading strategy that\n",
      "only reads an article once without any subsequent testing or evaluation.\n",
      "Comparing to the conventional approach that reads articles multiple times, YORO\n",
      "evaluates language models' comprehension, general knowledge, and performance in\n",
      "related tasks both before and after the reading process, and finds that the\n",
      "conventional approach is biased. We propose a new reading strategy, YORO, which\n",
      "only reads an article once without any subsequent testing or evaluation. Comparing\n",
      "to the conventional approach that reads articles multiple times, YORO evaluates\n",
      "language models' comprehension, general knowledge, and performance in related\n",
      "tasks both before and then after the reading process, and finds that the\n",
      "conventional approach is biased. Our analysis finds that the conventional\n",
      "approach assumes that reading articles multiple times can improve models'\n",
      "comprehension and general knowledge, while YORO finds that this assumption may\n",
      "be\n"
     ]
    }
   ],
   "source": [
    "# Generate the response\n",
    "with torch.no_grad():\n",
    "    output = peft_model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=512,\n",
    "        num_beams=5,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        top_k=50,\n",
    "        repetition_penalty=1.5,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.convert_tokens_to_ids(eos_token),\n",
    "        pad_token_id=tokenizer.convert_tokens_to_ids(pad_token)\n",
    "    )\n",
    "\n",
    "# Decode and extract the assistant's response\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bf73fa-7ec6-4cc7-9ed9-46437d45235d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
